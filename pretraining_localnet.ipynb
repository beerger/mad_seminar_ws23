{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Run these cells only when in Google Colab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/beerger/mad_seminar_ws23.git\n",
    "# Move all content to the current directory\n",
    "!mv ./mad_seminar_ws23/* ./\n",
    "# Remove the empty directory\n",
    "!rm -rf mad_seminar_ws23/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages\n",
    "!pip install pytorch_lightning --quiet\n",
    "!pip install lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for Local-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from google.colab import drive\n",
    "\n",
    "from model.local_net import LocalNet\n",
    "from model.model_utils import load_resnet_18_teacher_model\n",
    "from model.student_training_module import StudentTrainingModule\n",
    "from data_loader.localnet_data_loader import LocalNetDataModule\n",
    "from model.one_layer_decoder import OneLayerDecoder\n",
    "\n",
    "# autoreload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training\n",
    "\n",
    "The following code blocks will be part of the training of Local-Net. This is refered to as the pre-training of the framework, since the Local-Nets parameters will be fixed during training of Global-Net and DAD-head. This consists of two major steps:\n",
    "\n",
    "* **Distillation**: on ImageNet, where the teacher network is pretrained ResNet-18.\n",
    "* **Fine-tuning**: on some certain category of MVTec AD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/local_net_distillation.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Reproducibility\n",
    "pl.seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount current Colab session to Google Drive (training/val images are stored here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will provide you with an authentication link\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy data from Google Drive to Colab VM's local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy training and validation zips from Google Drive\n",
    "# Takes ~ 7 - 15 min\n",
    "!cp \"/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/train.zip\" \"/content/\"\n",
    "!cp \"/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/val.zip\" \"/content/\"\n",
    "\n",
    "# Unzip\n",
    "# Takes ~ 7 min\n",
    "!unzip \"/content/train.zip\" -d \"/content/train\"\n",
    "!unzip \"/content/val.zip\" -d \"/content/val\"\n",
    "\n",
    "# Delete the zip files to free up space\n",
    "!rm \"/content/train.zip\"\n",
    "!rm \"/content/val.zip\"\n",
    "\n",
    "# Move files to correct places\n",
    "!mv \"/content/train/content/train/* /content/train/\"\n",
    "!rm -rf \"/content/train/content\"\n",
    "!mv \"/content/val/content/val/*\" \"/content/val/\"\n",
    "!rm -rf \"/content/val/content\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data module for ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_image_paths = load_image_paths('/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/train_image_local_paths.json')\n",
    "val_image_paths = load_image_paths('/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/val_image_local_paths.json')\n",
    "\n",
    "data_module = LocalNetDataModule(\n",
    "    train_image_paths, \n",
    "    val_image_paths, \n",
    "    batch_size=config['batch_size'], \n",
    "    num_workers=4, \n",
    "    caching_strategy='none'\n",
    ")\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_paths)}\")\n",
    "print(f\"Number of validation images: {len(val_image_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot patches for Local-Net and ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure batch_size in data_module is equal to BATCH_SIZE\n",
    "\n",
    "BATCH_SIZE=config['batch_size']\n",
    "\n",
    "# Reverse the normalization process done by LocalNetDataModule\n",
    "# to avoid the following error:\n",
    "# WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "    tensor = tensor * std + mean  # Reverses the normalization in-place\n",
    "    return tensor.clamp(0, 1)  # Ensures the pixel values are within [0, 1]\n",
    "\n",
    "\n",
    "# Retrieve one batch of images\n",
    "patch_local, patch_resnet = next(iter(data_module.train_dataloader()))\n",
    "\n",
    "# Denormalize the patches for visualization\n",
    "patch_local = denormalize(patch_local)\n",
    "patch_resnet = denormalize(patch_resnet)\n",
    "\n",
    "fig, ax = plt.subplots(2, BATCH_SIZE, figsize=(20, 8))  # 2 rows, BATCH_SIZE columns\n",
    "\n",
    "# Plotting patch_local images in the first row\n",
    "for i in range(BATCH_SIZE):\n",
    "    # Permute the tensor to the format (H, W, C)\n",
    "    image = patch_local[i].permute(1, 2, 0)\n",
    "\n",
    "    # Display the image\n",
    "    ax[0, i].imshow(image.cpu().numpy())\n",
    "    ax[0, i].axis('off')\n",
    "\n",
    "# Plotting patch_resnet images in the second row\n",
    "for i in range(BATCH_SIZE):\n",
    "    # Permute the tensor to the format (H, W, C)\n",
    "    image = patch_resnet[i].permute(1, 2, 0)\n",
    "\n",
    "    # Display the image\n",
    "    ax[1, i].imshow(image.cpu().numpy())\n",
    "    ax[1, i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up all models for distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'device' is either 'cuda' if a GPU is available, otherwise 'cpu'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "local_net = LocalNet(config).to(device)\n",
    "resnet_18 = load_resnet_18_teacher_model('resnet18-5c106cde.pth', device)\n",
    "decoder = OneLayerDecoder(config['local_net_output_dimensions'], \n",
    "                          config['resnet_output_dimensions']).to(device)\n",
    "\n",
    "student_train_module = StudentTrainingModule(\n",
    "    config, \n",
    "    student_model=local_net, \n",
    "    teacher_model=resnet_18, \n",
    "    decoder=decoder, \n",
    "    mode='distillation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given by paper is batch size of 64 for 50k iterations\n",
    "# Need to calculate max_epochs\n",
    "total_iterations = config['iterations']\n",
    "batch_size = config['batch_size']\n",
    "num_training_images = len(train_image_paths)\n",
    "# Calculate max_epochs\n",
    "max_epochs = total_iterations / (num_training_images / batch_size)\n",
    "max_epochs = int(max_epochs) + (max_epochs % 1 > 0)  # round up if not an integer\n",
    "print(f\"Calculated max_epochs: {max_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Setup the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"/content/drive/MyDrive/AnomalyDetection/LocalNet/Distillation/Checkpoints\",  # Path where checkpoints will be saved\n",
    "    filename=\"{epoch}-{val_loss:.2f}\",  # Filename template\n",
    "    monitor=\"val_loss\",  # Metric to monitor for saving\n",
    "    every_n_epochs=1,  # Save every epoch\n",
    "    save_weights_only=True  # If True, save only the model weights, not the full model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup new trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=[\n",
    "        pl.loggers.TensorBoardLogger(save_dir='./')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup trainer from checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change <CHECK_POINT.ckpt> to a valid checkpoint file located in\n",
    "# /content/drive/MyDrive/AnomalyDetection/LocalNet/Checkpoints/\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    resume_from_checkpoint=\"/content/drive/MyDrive/AnomalyDetection/LocalNet/Distillation/Checkpoints/<CHECK_POINT.ckpt>\",\n",
    "    logger=[\n",
    "        pl.loggers.TensorBoardLogger(save_dir='./')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(student_train_module, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save distilled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(local_net.state_dict(), '/content/drive/MyDrive/AnomalyDetection/LocalNet/Distillation/Trained Models/local_net_distilled.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning\n",
    "\n",
    "Local-Net has now been distilled from pre-trained ResNet-18 on ImageNet, and will in this part be fine-tuned. It is fine-tuned into a specific category in MVTec AD with the same loss as that in distillation. Here, the category ***zippers*** have been chosen, as it looks interesting, and it also got 0.99 in pixel-level AUROC, and 0.992 in per-region-overlap (PRO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/local_net_fine_tune.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Reproducibility\n",
    "pl.seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will provide you with an authentication link\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy zipped file of zipper dataset from Google Drive to current Colab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/AnomalyDetection/Datasets/MVTec/zipper.tar.xz\" \"/content/\"\n",
    "# Unzip it\n",
    "!tar -xf /content/zipper.tar.xz -C /content/\n",
    "# Remove zip file\n",
    "!rm -rf zipper.tar.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get paths to training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory you want to list\n",
    "train_directory = '/content/zipper/train/good/'\n",
    "\n",
    "# Get a list of all files in the train_directory\n",
    "file_list = [train_directory + f for f in os.listdir(train_directory) if os.path.isfile(os.path.join(train_directory, f))]\n",
    "\n",
    "assert len(file_list) == 240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming file_paths is your list of 240 image file paths\n",
    "train_image_paths, val_image_paths = train_test_split(file_list, test_size=0.1, random_state=config['seed'])  # Adjust test_size as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data module for MVTec AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = LocalNetDataModule(\n",
    "    train_image_paths, \n",
    "    val_image_paths, \n",
    "    batch_size=config['batch_size'], \n",
    "    num_workers=2, \n",
    "    caching_strategy='at-init'\n",
    ")\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_paths)}\")\n",
    "print(f\"Number of validation images: {len(val_image_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot patches for Local-Net and ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure batch_size in data_module is equal to BATCH_SIZE\n",
    "\n",
    "BATCH_SIZE=config['batch_size']\n",
    "\n",
    "# Reverse the normalization process done by LocalNetDataModule\n",
    "# to avoid the following error:\n",
    "# WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "    tensor = tensor * std + mean  # Reverses the normalization in-place\n",
    "    return tensor.clamp(0, 1)  # Ensures the pixel values are within [0, 1]\n",
    "\n",
    "\n",
    "# Retrieve one batch of images\n",
    "patch_local, patch_resnet = next(iter(data_module.train_dataloader()))\n",
    "\n",
    "# Denormalize the patches for visualization\n",
    "patch_local = denormalize(patch_local)\n",
    "patch_resnet = denormalize(patch_resnet)\n",
    "\n",
    "fig, ax = plt.subplots(2, BATCH_SIZE, figsize=(20, 8))  # 2 rows, BATCH_SIZE columns\n",
    "\n",
    "# Plotting patch_local images in the first row\n",
    "for i in range(BATCH_SIZE):\n",
    "    # Permute the tensor to the format (H, W, C)\n",
    "    image = patch_local[i].permute(1, 2, 0)\n",
    "\n",
    "    # Display the image\n",
    "    ax[0, i].imshow(image.cpu().numpy())\n",
    "    ax[0, i].axis('off')\n",
    "\n",
    "# Plotting patch_resnet images in the second row\n",
    "for i in range(BATCH_SIZE):\n",
    "    # Permute the tensor to the format (H, W, C)\n",
    "    image = patch_resnet[i].permute(1, 2, 0)\n",
    "\n",
    "    # Display the image\n",
    "    ax[1, i].imshow(image.cpu().numpy())\n",
    "    ax[1, i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up all models for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'device' is either 'cuda' if a GPU is available, otherwise 'cpu'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load distilled local_net from Google Drive\n",
    "local_net = LocalNet().to(device)\n",
    "# Load the state dictionary from the saved file\n",
    "local_state_dict = torch.load('/content/drive/MyDrive/AnomalyDetection/LocalNet/Distillation/Trained Models/V2/local_net_distilled_v2.pth', map_location=device)\n",
    "# Update the local_net model's state dictionary\n",
    "local_net.load_state_dict(local_state_dict)\n",
    "\n",
    "resnet_18 = load_resnet_18_teacher_model('resnet18-5c106cde.pth', device)\n",
    "decoder = OneLayerDecoder(config['local_net_output_dimensions'], \n",
    "                          config['resnet_output_dimensions']).to(device)\n",
    "\n",
    "decoder_state_dict = torch.load('/content/drive/MyDrive/AnomalyDetection/LocalNet/Distillation/Trained Models/V2/decoder_v2.pth')\n",
    "\n",
    "decoder.load_state_dict(decoder_state_dict)\n",
    "\n",
    "student_train_module = StudentTrainingModule(\n",
    "    config, \n",
    "    student_model=local_net, \n",
    "    teacher_model=resnet_18, \n",
    "    decoder=decoder, \n",
    "    mode='finetuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given by paper is batch size of 64 for 50k iterations\n",
    "# Need to calculate max_epochs\n",
    "total_iterations = config['iterations']\n",
    "batch_size = config['batch_size']\n",
    "num_training_images = len(train_image_paths)\n",
    "# Calculate max_epochs\n",
    "max_epochs = total_iterations / (num_training_images / batch_size)\n",
    "max_epochs = int(max_epochs) + (max_epochs % 1 > 0)  # round up if not an integer\n",
    "print(f\"Calculated max_epochs: {max_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Setup the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"/content/drive/MyDrive/AnomalyDetection/LocalNet/Fine-tuning/Checkpoints\",  # Path where checkpoints will be saved\n",
    "    filename=\"{epoch}-{val_loss:.2f}\",  # Filename template\n",
    "    monitor=\"val_loss\",  # Metric to monitor for saving\n",
    "    every_n_epochs=1,  # Save every epoch\n",
    "    save_weights_only=True,  # If True, save only the model weights, not the full model\n",
    "    save_top_k=3,  # Save the top 3 checkpoints based on val_loss\n",
    "    save_last=True,  # Also save the last checkpoint to resume training later\n",
    "    verbose=True  # If True, print a message to stdout for each save\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup new trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=[\n",
    "        pl.loggers.TensorBoardLogger(save_dir='./')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup trainer from checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change <CHECK_POINT.ckpt> to a valid checkpoint file located in\n",
    "# /content/drive/MyDrive/AnomalyDetection/LocalNet/Fine-tuning/Checkpoints\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    resume_from_checkpoint=\"/content/drive/MyDrive/AnomalyDetection/LocalNet/Fine-tuning/Checkpoints/<CHECK_POINT.ckpt>\",\n",
    "    logger=[\n",
    "        pl.loggers.TensorBoardLogger(save_dir='./')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(student_train_module, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(local_net.state_dict(), '/content/drive/MyDrive/AnomalyDetection/LocalNet/Fine-tuning/Trained Models/local_net_finetuned.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model by first loading given checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_net = LocalNet()\n",
    "resnet_18 = load_resnet_18_teacher_model('resnet18-5c106cde.pth', device)\n",
    "decoder = OneLayerDecoder(128, 512)\n",
    "\n",
    "student_train_module = StudentTrainingModule(\n",
    "    config, \n",
    "    student_model=local_net, \n",
    "    teacher_model=resnet_18, \n",
    "    decoder=decoder, \n",
    "    mode='finetuning'\n",
    ")\n",
    "\n",
    "# Replace with correct checkpoint path\n",
    "checkpoint = torch.load(\"/content/drive/MyDrive/AnomalyDetection/LocalNet/Fine-tuning/Checkpoints/V4/epoch=3535-val_loss=1890.43.ckpt\")\n",
    "student_train_module.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "local_net = student_train_module.student_model\n",
    "\n",
    "# Save the state dictionaries of the individual models\n",
    "torch.save(local_net.state_dict(), '/content/drive/MyDrive/AnomalyDetection/LocalNet/Fine-tuning/Trained Models/V4/local_net_finetuned_v4.pth')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
