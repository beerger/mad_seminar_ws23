{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Run these cells only when in Google Colab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Clone the repository\n",
    "# !git clone https://github.com/beerger/mad_seminar_ws23.git\n",
    "# # Move all content to the current directory\n",
    "# !mv ./mad_seminar_ws23/* ./\n",
    "# # Remove the empty directory\n",
    "# !rm -rf mad_seminar_ws23/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download the data\n",
    "# !wget <link you got from your supervisor>\n",
    "# # Extract the data\n",
    "# !unzip -q ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install additional packages\n",
    "# !pip install pytorch_lightning --quiet\n",
    "# !pip install lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from model.model import get_model\n",
    "from data_loader import TrainDataModule, get_all_test_dataloaders\n",
    "\n",
    "# autoreload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-training\n",
    "\n",
    "Until next numbered step the following code blocks will be part of the training of Local-Net. This is refered to as the pre-training of the framework, since the Local-Nets parameters will be fixed during training of Global-Net and DAD-head. This consists of two major steps:\n",
    "\n",
    "* **Distillation**: on ImageNet, where the teacher network is pretrained ResNet-18.\n",
    "* **Fine-tuning**: on some certain category of MVTec AD\n",
    "\n",
    "Pre-processing in accordance (*) to ResNet-18 documentation\n",
    "@ https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html\n",
    "\n",
    "(*) According to documentation it's first resized to 256x256 then\n",
    "center cropped to 224x224. This step has been skipped, \n",
    "and it is instead resized directly to 224x224. \n",
    "The reason for this is because the input patch size to Local-Net is 33x33\n",
    "and ResNet-18 has input size 224x224, \n",
    "meaning that resizing to 256x256 and then cropping to desired size (224x224)\n",
    "would result in altering the original spatial relationships and scale of the features of the image.\n",
    "This could potentially lead to a mismatch when comparing features extracted from the resized and \n",
    "cropped image by ResNet-18 with those extracted from the original 33x33 image by Local-Net.\n",
    "\n",
    "Pre-processing the data for distillation consists of 4 major steps:\n",
    "\n",
    "1. Load images from Image-Net\n",
    "2. Resize images to 256 x 256 (done by most applications, and mentioned in Supplementary Material)\n",
    "3. Extract 33 x 33 patches from each resized image\n",
    "4. Create two separate transform pipelines\n",
    "    * For Local-Net: Convert the 33x33 patches to PyTorch tensors and normalize them\n",
    "    * For ResNet-18 (teacher model): Resize the 33x33 patches to 224x224, then convert to tensors and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install hugginface cli for ImageNet\n",
    "# !pip install -U \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:\n",
    "\n",
    "from datasets import load_dataset\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"imagenet-1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Distillation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/local_net_distillation.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Reproducibility\n",
    "pl.seed_everything(config['seed'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
