{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Dataset Setup Notebook\n",
    "\n",
    "This notebook is dedicated to the initial setup and preparation of the ImageNet dataset for machine learning tasks. It encompasses the following key processes:\n",
    "\n",
    "1. **Downloading the Dataset**: Automates the download of the ImageNet dataset (both training and validation parts) from the official source.\n",
    "\n",
    "2. **Extracting the Dataset**: Methodically extracts the downloaded dataset, which is initially in compressed tar file format, into a structured directory format suitable for machine learning models. This includes creating separate directories for each class in the training set.\n",
    "\n",
    "3. **File Path Extraction**: Iterates through the extracted directories to compile a comprehensive list of file paths for all images. This list is crucial for efficient data loading during the model training process.\n",
    "\n",
    "4. **Saving File Paths**: Saves the generated list of image file paths to a file on Google Drive. This enables easy and quick access to the dataset in future sessions or in other notebooks, particularly in model training and validation stages.\n",
    "\n",
    "Overall, this notebook is intended to streamline the data handling aspect of working with the large-scale ImageNet dataset, ensuring that subsequent stages of the project, such as model training and evaluation, can proceed smoothly and efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount Google Drive to current Colab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "# Will provide you with an authentication link\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only call in case drive needs to be remounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set target directory for download of ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "target_dir = '/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/TrainValTar'\n",
    "os.makedirs(target_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download train tar file from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar -P {target_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download validation tar file from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -c https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar -P {target_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run script to extract downloaded tar file from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd scripts/\n",
    "!chmod +x extract_imagenet.sh\n",
    "!./extract_imagenet.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run script that count total amount of train images (due to Google Colab/Drive sync problems, not all training images from ImageNet, have been unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/\\r$//' count_train_images_imagenet.sh\n",
    "!chmod +x count_train_images_imagenet.sh\n",
    "!./count_train_images_imagenet.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run script that count total amount of validation images (due to Google Colab/Drive sync problems, not all validation images from ImageNet, have been unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's/\\r$//' count_val_images_imagenet.sh\n",
    "!chmod +x count_val_images_imagenet.sh\n",
    "!./count_val_images_imagenet.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of a all image paths in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_image_paths_1(root_dir):\n",
    "    image_paths = []\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.JPG', '.JPEG')):\n",
    "                full_path = os.path.join(subdir, file)\n",
    "                image_paths.append(full_path)\n",
    "    return image_paths\n",
    "\n",
    "train_dir = '/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/train'\n",
    "train_image_paths = get_image_paths_1(train_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training image paths to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the list of paths as a JSON file\n",
    "with open('/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/train_image_paths.json', 'w') as f:\n",
    "    json.dump(train_image_paths, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training image paths from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of paths from the JSON file\n",
    "with open('/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/train_image_paths.json', 'r') as f:\n",
    "    train_image_paths = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of a all image paths in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_image_paths_2(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "val_dir = '/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/val'\n",
    "val_image_paths = get_image_paths_2(val_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save validation image paths to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the list of validation image paths as a JSON file\n",
    "with open('/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/val_image_paths.json', 'w') as f:\n",
    "    json.dump(val_image_paths, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load validation image paths from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of validation image paths from the JSON file\n",
    "with open('/content/drive/MyDrive/AnomalyDetection/Datasets/ImageNet/val_image_paths.json', 'r') as f:\n",
    "    val_image_paths = json.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
