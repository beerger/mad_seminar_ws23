{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Run these cells only when in Google Colab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/beerger/mad_seminar_ws23.git\n",
    "# Move all content to the current directory\n",
    "!mv ./mad_seminar_ws23/* ./\n",
    "# Remove the empty directory\n",
    "!rm -rf mad_seminar_ws23/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages\n",
    "!pip install pytorch_lightning --quiet\n",
    "!pip install lpips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import yaml\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from google.colab import drive\n",
    "\n",
    "from model.local_net import LocalNet\n",
    "from model.dad import DADHead\n",
    "from model.iad import iad_head\n",
    "from model.global_net import GlobalNet\n",
    "from data_loader.mvtec_inference_data_loader import MVTecInferenceDataModule\n",
    "from model.anomaly_detector import AnomalyDetector\n",
    "\n",
    "# autoreload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount current Colab session to Google Drive (training/val images are stored here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will provide you with an authentication link\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy zipped file of zipper dataset from Google Drive to current Colab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/AnomalyDetection/Datasets/MVTec/zipper.tar.xz\" \"/content/\"\n",
    "# Unzip it\n",
    "!tar -xf /content/zipper.tar.xz -C /content/\n",
    "# Remove zip file\n",
    "!rm -rf zipper.tar.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get paths to test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory you want to list\n",
    "train_directory = '/content/zipper/test/'\n",
    "\n",
    "test_file_paths = []\n",
    "for root, dirs, files in os.walk(train_directory, topdown=False):\n",
    "   for name in files:\n",
    "      test_file_paths.append(os.path.join(root, name))\n",
    "\n",
    "assert len(test_file_paths) == 151\n",
    "print(test_file_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = MVTecInferenceDataModule(\n",
    "    test_file_paths, \n",
    "    batch_size=1, \n",
    "    num_workers=0, \n",
    "    caching_strategy='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display inference images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure batch_size in data_module is equal to BATCH_SIZE\n",
    "\n",
    "BATCH_SIZE=4\n",
    "\n",
    "images = next(iter(data_module.test_dataloader()))\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "  ax[i].imshow(images[i].permute(1, 2, 0).cpu().numpy())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that AnomalyDetector creates correct patches and binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_detector = AnomalyDetector(None, None, None, none=True)\n",
    "patches, binary_masks = anomaly_detector.create_patches_and_masks(images[0])\n",
    "\n",
    "# Reverse the normalization process done by data module\n",
    "# to avoid the following error:\n",
    "# WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "    tensor = tensor * std + mean  # Reverses the normalization in-place\n",
    "    return tensor.clamp(0, 1)  # Ensures the pixel values are within [0, 1]\n",
    "\n",
    "# Denormalize\n",
    "for i, patch in enumerate(patches):\n",
    "  patches[i] = denormalize(patch)\n",
    "\n",
    "# Plot image\n",
    "image = images[0].squeeze(0)\n",
    "plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "plt.show()\n",
    "  \n",
    "# Plot all (overlapping) patches\n",
    "fig1, ax1 = plt.subplots(20, 20, figsize=(20, 20))\n",
    "for j in range(20):\n",
    "  for i in range(20):\n",
    "    ax1[j][i].imshow(patches[i+j*20].squeeze(0).permute(1, 2, 0).cpu().numpy())\n",
    "    ax1[j][i].axis('off')\n",
    "\n",
    "# Plot all (overlappin) binary masks\n",
    "fig2, ax2 = plt.subplots(20, 20, figsize=(20, 20))\n",
    "for j in range(20):\n",
    "  for i in range(20):\n",
    "    ax2[j][i].imshow(binary_masks[i+j*20].squeeze(0).cpu().numpy(), cmap='gray', interpolation='none')\n",
    "    #ax2[j][i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Anomaly Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'device' is either 'cuda' if a GPU is available, otherwise 'cpu'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load all state dictionary from Google Drive\n",
    "local_state_dict = torch.load('/content/drive/MyDrive/AnomalyDetection/LocalNet/Fine-tuning/Trained Models/V4/local_net_finetuned_v4.pth', map_location=device)\n",
    "global_state_dict = torch.load('/content/drive/MyDrive/AnomalyDetection/GlobalNet_DAD/Trained Models/V5/global_net_v5.pth', map_location=device)\n",
    "dad_state_dict = torch.load('/content/drive/MyDrive/AnomalyDetection/GlobalNet_DAD/Trained Models/V5/dad_head_v5.pth', map_location=device)\n",
    "\n",
    "# Initialise all networks\n",
    "local_net = LocalNet().to(device)\n",
    "global_net = GlobalNet().to(device)\n",
    "dad_head = DADHead().to(device)\n",
    "\n",
    "# Update all network's state dictionaries\n",
    "local_net.load_state_dict(local_state_dict)\n",
    "global_net.load_state_dict(global_state_dict)\n",
    "dad_head.load_state_dict(dad_state_dict)\n",
    "\n",
    "anomaly_detector = AnomalyDetector(local_net, global_net, dad_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[3]\n",
    "anomaly_score_map = anomaly_detector.detect_anomalies(image.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Apply a Gaussian blur to the anomaly map\n",
    "smoothed_anomaly_map = gaussian_filter(anomaly_score_map, sigma=5)  # You can adjust the sigma value\n",
    "\n",
    "# Visualize the smoothed anomaly map\n",
    "plt.imshow(smoothed_anomaly_map, cmap='jet')  # Using the same colormap\n",
    "plt.colorbar()  # To see the range of values on the smoothed anomaly score map\n",
    "plt.axis('off')  # Turn off axis numbers and ticks\n",
    "plt.show()\n",
    "\n",
    "# Convert to numpy array and transpose to HWC format for image display\n",
    "image_np = image.cpu().detach().numpy().transpose(1, 2, 0)\n",
    "image_pil = Image.fromarray((image_np * 255).astype(np.uint8))\n",
    "\n",
    "# Normalize the resized anomaly map to the range [0, 1]\n",
    "normalized_anomaly_map = (smoothed_anomaly_map - np.min(smoothed_anomaly_map)) / (np.max(smoothed_anomaly_map) - np.min(smoothed_anomaly_map))\n",
    "\n",
    "# Apply a colormap to the normalized anomaly map\n",
    "colormap = plt.cm.jet\n",
    "normed_data = Normalize(0, 1)(normalized_anomaly_map)\n",
    "mapped_data = colormap(normed_data)\n",
    "\n",
    "# Convert the RGBA image to an RGB image\n",
    "mapped_data_rgb = (mapped_data[..., :3] * 255).astype(np.uint8)\n",
    "\n",
    "# Overlay the colored anomaly map onto the original image\n",
    "blended_image = Image.blend(image_pil.convert(\"RGBA\"), Image.fromarray(mapped_data_rgb).convert(\"RGBA\"), alpha=0.48)\n",
    "\n",
    "# Show the blended image\n",
    "plt.imshow(blended_image)\n",
    "plt.axis('off')  # Turn off axis numbers and ticks\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
